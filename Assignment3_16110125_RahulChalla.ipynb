{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNtciHW36hK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsUWp2M16kIp",
        "colab_type": "code",
        "outputId": "6cc40794-74f6-4ad8-f96f-3714c161f8ee",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-491fddd6-c41c-4557-8ad9-f37a60e9bc0c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-491fddd6-c41c-4557-8ad9-f37a60e9bc0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.txt to test.txt\n",
            "Saving train.txt to train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXoQv1HAeZSm",
        "colab_type": "text"
      },
      "source": [
        "###Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B2kUGr3HeVvh",
        "colab": {}
      },
      "source": [
        "f = open('train.txt','r',encoding = \"utf8\")\n",
        "traindata = f.readlines()\n",
        "traindata = [i.lower() for i in traindata]\n",
        "f1 = open('test.txt','r',encoding = \"utf8\")\n",
        "testdata = f1.readlines()\n",
        "testdata = [i.lower() for i in testdata]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VsdVeWmehm-",
        "colab_type": "text"
      },
      "source": [
        "### Filtering Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aTBIclrleVvg",
        "colab": {}
      },
      "source": [
        "metaindices = []\n",
        "for i in range(len(traindata)):\n",
        "  if(\"meta\\t\" in traindata[i]):\n",
        "    metaindices.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e21b4e0a-124e-417a-db21-16ece36bda31",
        "id": "Xq6AS3KReVva",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(metaindices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "se758TGpeVvX",
        "colab": {}
      },
      "source": [
        "metatestindices = []\n",
        "for i in range(len(testdata)):\n",
        "  if(\"meta\\t\" in testdata[i]):\n",
        "    metatestindices.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "548a4ea1-8e30-46af-aba1-64697bfcb37e",
        "id": "mQCbAhKreVvR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(metatestindices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLeB7VnGel1X",
        "colab_type": "text"
      },
      "source": [
        "### Tweets separation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PM85lEdheVvP",
        "colab": {}
      },
      "source": [
        "testtweets = []\n",
        "strng = \"\"\n",
        "for i in range(1,len(testdata)):\n",
        "  if(testdata[i] == \"\\n\"):\n",
        "    continue\n",
        "  if(i not in metatestindices):\n",
        "    strng = strng + testdata[i][:testdata[i].index(\"\\t\")] + \" \"\n",
        "  else:\n",
        "    strng.strip()\n",
        "    testtweets.append(strng)\n",
        "    strng = \"\"\n",
        "  if(i == len(testdata)-2):\n",
        "    strng.strip()\n",
        "    testtweets.append(strng)\n",
        "    strng = \"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sb4Uw9OfeVvN",
        "colab": {}
      },
      "source": [
        "traintweets = []\n",
        "strng = \"\"\n",
        "for i in range(1,len(traindata)):\n",
        "  if(traindata[i] == \"\\n\"):\n",
        "    continue\n",
        "  if(i not in metaindices):\n",
        "    strng = strng + traindata[i][:traindata[i].index(\"\\t\")] + \" \"\n",
        "  else:\n",
        "    strng.strip()\n",
        "    traintweets.append(strng)\n",
        "    strng = \"\"\n",
        "  if(i == len(traindata)-2):\n",
        "    strng.strip()\n",
        "    traintweets.append(strng)\n",
        "    strng = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db9bc521-f7c8-464e-a2f4-1c97dec91b90",
        "id": "8thfahC2eVvF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(traintweets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "90dfa710-2bdb-4766-c979-7dfc04279a91",
        "id": "W_3WjHyKeVu_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(testtweets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "23700c4b-73be-4593-c02c-147131025a55",
        "id": "4awYHt1weVu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(traindata)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "426280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ5nAtDoeyDI",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U87rtMqleVu7",
        "colab": {}
      },
      "source": [
        "d = {}\n",
        "index=0\n",
        "max_length=0\n",
        "for i in traintweets:\n",
        "  max_length = max(max_length, len(i.split(' ')))\n",
        "  for j in i.split(' '):\n",
        "    if j not in d:\n",
        "      d[j] = index\n",
        "      index+=1\n",
        "# for i in testtweets:\n",
        "#   max_length = max(max_length, len(i.split(' ')))\n",
        "#   for j in i.split(' '):\n",
        "#     if j not in d:\n",
        "#       d[j] = index\n",
        "      #index+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8563200d-b400-4cab-daba-448c231bb319",
        "id": "KpkBtdQUeVu4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TzSbi6nbeVuu",
        "colab": {}
      },
      "source": [
        "# train_embedding = np.zeros((len(traintweets), len(d)))\n",
        "# test_embedding = np.zeros((len(testtweets), len(d)))\n",
        "\n",
        "# for cnt, i in enumerate(traintweets):\n",
        "#   for j in i.split(' '):\n",
        "#     train_embedding[cnt, d[j]] = 1\n",
        "  \n",
        "# for cnt, i in enumerate(testtweets):\n",
        "#   for j in i.split(' '):\n",
        "#     if j in d:\n",
        "#       test_embedding[cnt, d[j]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-_BQFI9VeVur",
        "colab": {}
      },
      "source": [
        "#len(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1OO-y4PQeVup",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "429a1058-5a3a-4bb3-cdeb-45318e862fe2",
        "id": "KV75iDndeVuo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qq8UgrASeVun"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_swPX8S7eVul",
        "colab": {}
      },
      "source": [
        "# tokenizer_obj = Tokenizer()\n",
        "# total_tweets = traintweets+testtweets\n",
        "# tokenizer_obj.fit_on_texts(total_tweets)\n",
        "# train_tokens = tokenizer_obj.texts_to_sequences(traintweets)\n",
        "# test_tokens = tokenizer_obj.texts_to_sequences(testtweets)\n",
        "# trainpad = pad_sequences(train_tokens,maxlen = max_length, padding = \"post\")\n",
        "# testpad = pad_sequences(test_tokens,maxlen = max_length, padding = \"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eb3d5899-c10c-4ee8-a96e-5cbf05b2edfb",
        "id": "spRc6XD1eVuh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHs9f5gje5v-",
        "colab_type": "text"
      },
      "source": [
        "### Train_y and Test_y generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KnoR9ngjeVug",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "for i in metaindices:\n",
        "  label = traindata[i].split(\"\\t\")[-1][:-1]\n",
        "  if label=='positive':\n",
        "    labels.append(0)\n",
        "  elif label=='negative':\n",
        "    labels.append(1)\n",
        "  else:\n",
        "    labels.append(2)\n",
        "\n",
        "train_y = to_categorical(labels, num_classes=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z6CW2kd5eVuc",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "for i in metatestindices:\n",
        "  label = testdata[i].split(\"\\t\")[-1][:-1]\n",
        "  if label=='positive':\n",
        "    labels.append(0)\n",
        "  elif label=='negative':\n",
        "    labels.append(1)\n",
        "  else:\n",
        "    labels.append(2)\n",
        "test_y = to_categorical(labels, num_classes=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3e5c5202-9ed1-4717-a752-3bd1898db8e3",
        "id": "4w51EHWqeVuY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y.shape,test_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15131, 3), (1869, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QWDEXAtReVuV",
        "colab": {}
      },
      "source": [
        "#[traindata[i].split(\"\\t\")[-1][:-1] for i in metaindices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dIXKc41fAHB",
        "colab_type": "text"
      },
      "source": [
        "### TfIdf Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNGHkVpueVuQ",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(traintweets+testtweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q9qkeEhTeVuO",
        "colab": {}
      },
      "source": [
        "train_embedding = vectorizer.transform(traintweets)\n",
        "test_embedding = vectorizer.transform(testtweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "csDkgPpDeVuJ",
        "colab": {}
      },
      "source": [
        "train_embedding = train_embedding.toarray()\n",
        "test_embedding = test_embedding.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5MpHyKGfFG7",
        "colab_type": "text"
      },
      "source": [
        "### Dimensional Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fic6JOXNeVuG",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EkUTafGweVuD",
        "colab": {}
      },
      "source": [
        "reducer = TruncatedSVD(n_components=200)\n",
        "train_embedding_ = reducer.fit_transform(train_embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Si-Bk6nCeVt_",
        "colab": {}
      },
      "source": [
        "test_embedding_ = reducer.transform(test_embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e586b7c8-370d-44a5-c325-eac1d670c3d3",
        "id": "VTcvL0ADeVt5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_embedding_.shape,test_embedding_.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15131, 200), (1869, 200))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qt6BIDYfNyv",
        "colab_type": "text"
      },
      "source": [
        "### Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpxwR1Q4i5gJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xMFzQTueVt1",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(train_embedding.shape[1],)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(.1))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(.1))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "filepath=\"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3b6b8b2d-ecca-4111-e240-232a6129501a",
        "id": "qBcJFRFZeVtz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(train_y,axis=1)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ffd6970b-ff5a-4f6c-c038-b9fa77464449",
        "id": "VTUOYfjYeVtx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 64)                3507264   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 3,508,355\n",
            "Trainable params: 3,508,355\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "994129a9-8bb7-4a90-eeb5-700e3d9130b0",
        "id": "jGpg0ypUeVtr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_embedding, train_y, batch_size=1024,epochs=200,validation_data=(test_embedding, test_y),callbacks=callbacks_list)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15131 samples, validate on 1869 samples\n",
            "Epoch 1/200\n",
            "15131/15131 [==============================] - 4s 285us/step - loss: 0.4252 - acc: 0.9036 - val_loss: 0.9388 - val_acc: 0.5554\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.56073\n",
            "Epoch 2/200\n",
            "15131/15131 [==============================] - 4s 278us/step - loss: 0.3439 - acc: 0.9270 - val_loss: 0.9635 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.56073\n",
            "Epoch 3/200\n",
            "15131/15131 [==============================] - 4s 278us/step - loss: 0.2677 - acc: 0.9492 - val_loss: 0.9970 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.56073\n",
            "Epoch 4/200\n",
            "15131/15131 [==============================] - 4s 279us/step - loss: 0.2094 - acc: 0.9609 - val_loss: 1.0329 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.56073\n",
            "Epoch 5/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.1654 - acc: 0.9718 - val_loss: 1.0779 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.56073\n",
            "Epoch 6/200\n",
            "15131/15131 [==============================] - 4s 278us/step - loss: 0.1321 - acc: 0.9780 - val_loss: 1.1147 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.56073\n",
            "Epoch 7/200\n",
            "15131/15131 [==============================] - 4s 280us/step - loss: 0.1081 - acc: 0.9819 - val_loss: 1.1528 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.56073\n",
            "Epoch 8/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0894 - acc: 0.9860 - val_loss: 1.1896 - val_acc: 0.5233\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.56073\n",
            "Epoch 9/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0766 - acc: 0.9876 - val_loss: 1.2268 - val_acc: 0.5195\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.56073\n",
            "Epoch 10/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0655 - acc: 0.9879 - val_loss: 1.2626 - val_acc: 0.5190\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.56073\n",
            "Epoch 11/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0573 - acc: 0.9898 - val_loss: 1.2989 - val_acc: 0.5195\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.56073\n",
            "Epoch 12/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0511 - acc: 0.9896 - val_loss: 1.3338 - val_acc: 0.5147\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.56073\n",
            "Epoch 13/200\n",
            "15131/15131 [==============================] - 4s 278us/step - loss: 0.0449 - acc: 0.9904 - val_loss: 1.3691 - val_acc: 0.5158\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.56073\n",
            "Epoch 14/200\n",
            "15131/15131 [==============================] - 4s 279us/step - loss: 0.0414 - acc: 0.9907 - val_loss: 1.4009 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.56073\n",
            "Epoch 15/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0354 - acc: 0.9917 - val_loss: 1.4308 - val_acc: 0.5169\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.56073\n",
            "Epoch 16/200\n",
            "15131/15131 [==============================] - 4s 278us/step - loss: 0.0325 - acc: 0.9917 - val_loss: 1.4641 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.56073\n",
            "Epoch 17/200\n",
            "15131/15131 [==============================] - 4s 279us/step - loss: 0.0312 - acc: 0.9915 - val_loss: 1.4929 - val_acc: 0.5190\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.56073\n",
            "Epoch 18/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0290 - acc: 0.9923 - val_loss: 1.5195 - val_acc: 0.5179\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.56073\n",
            "Epoch 19/200\n",
            "15131/15131 [==============================] - 4s 277us/step - loss: 0.0257 - acc: 0.9932 - val_loss: 1.5502 - val_acc: 0.5163\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.56073\n",
            "Epoch 20/200\n",
            " 4096/15131 [=======>......................] - ETA: 2s - loss: 0.0261 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-00a9205923df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 192\u001b[0;31m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[1;32m    193\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC5G7sf7jeLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jHCQQSr_eVtn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "467ec7a4-e768-474a-c59c-811132c79a57"
      },
      "source": [
        "test_predictions = model.predict(test_embedding)\n",
        "precision_recall_fscore_support(np.argmax(test_y,axis = 1),np.argmax(test_predictions,axis = 1),average='macro')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5665106569867407, 0.5621714780411771, 0.5641001471644823, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDXq9GLpgVhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(train_embedding_.shape[1],)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(.1))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(.1))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "filepath=\"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPsiIuTFkOf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b457f26-41cc-4fc6-b99e-8ad75fccb168"
      },
      "source": [
        "model.fit(train_embedding_, train_y, batch_size=1024,epochs=200,validation_data=(test_embedding_, test_y),callbacks=callbacks_list)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15131 samples, validate on 1869 samples\n",
            "Epoch 1/200\n",
            "15131/15131 [==============================] - 1s 49us/step - loss: 1.0956 - acc: 0.3641 - val_loss: 1.0883 - val_acc: 0.4045\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.40449, saving model to weights.hdf5\n",
            "Epoch 2/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 1.0865 - acc: 0.3759 - val_loss: 1.0788 - val_acc: 0.4066\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.40449 to 0.40663, saving model to weights.hdf5\n",
            "Epoch 3/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 1.0746 - acc: 0.4038 - val_loss: 1.0674 - val_acc: 0.4468\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.40663 to 0.44676, saving model to weights.hdf5\n",
            "Epoch 4/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 1.0560 - acc: 0.4595 - val_loss: 1.0493 - val_acc: 0.4799\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.44676 to 0.47994, saving model to weights.hdf5\n",
            "Epoch 5/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 1.0265 - acc: 0.5257 - val_loss: 1.0239 - val_acc: 0.5056\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.47994 to 0.50562, saving model to weights.hdf5\n",
            "Epoch 6/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.9886 - acc: 0.5591 - val_loss: 0.9972 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.50562 to 0.55056, saving model to weights.hdf5\n",
            "Epoch 7/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.9453 - acc: 0.5844 - val_loss: 0.9675 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.55056 to 0.55324, saving model to weights.hdf5\n",
            "Epoch 8/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.9065 - acc: 0.5924 - val_loss: 0.9496 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.55324\n",
            "Epoch 9/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8768 - acc: 0.6005 - val_loss: 0.9393 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.55324\n",
            "Epoch 10/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8554 - acc: 0.6024 - val_loss: 0.9374 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.55324\n",
            "Epoch 11/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8500 - acc: 0.6027 - val_loss: 0.9407 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.55324\n",
            "Epoch 12/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8427 - acc: 0.6060 - val_loss: 0.9413 - val_acc: 0.5484\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.55324\n",
            "Epoch 13/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8366 - acc: 0.6070 - val_loss: 0.9463 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55324\n",
            "Epoch 14/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.8332 - acc: 0.6129 - val_loss: 0.9442 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55324\n",
            "Epoch 15/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8280 - acc: 0.6171 - val_loss: 0.9466 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.55324\n",
            "Epoch 16/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8295 - acc: 0.6090 - val_loss: 0.9486 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.55324\n",
            "Epoch 17/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8253 - acc: 0.6150 - val_loss: 0.9480 - val_acc: 0.5468\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.55324\n",
            "Epoch 18/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8215 - acc: 0.6214 - val_loss: 0.9480 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.55324\n",
            "Epoch 19/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8226 - acc: 0.6174 - val_loss: 0.9499 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.55324\n",
            "Epoch 20/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8224 - acc: 0.6159 - val_loss: 0.9515 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.55324\n",
            "Epoch 21/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8185 - acc: 0.6233 - val_loss: 0.9499 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.55324\n",
            "Epoch 22/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8182 - acc: 0.6174 - val_loss: 0.9514 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.55324\n",
            "Epoch 23/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8140 - acc: 0.6255 - val_loss: 0.9517 - val_acc: 0.5452\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.55324\n",
            "Epoch 24/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8122 - acc: 0.6240 - val_loss: 0.9538 - val_acc: 0.5420\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.55324\n",
            "Epoch 25/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8091 - acc: 0.6255 - val_loss: 0.9538 - val_acc: 0.5441\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.55324\n",
            "Epoch 26/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8088 - acc: 0.6264 - val_loss: 0.9543 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.55324\n",
            "Epoch 27/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.8058 - acc: 0.6249 - val_loss: 0.9554 - val_acc: 0.5457\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.55324\n",
            "Epoch 28/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8032 - acc: 0.6263 - val_loss: 0.9571 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.55324\n",
            "Epoch 29/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8041 - acc: 0.6245 - val_loss: 0.9555 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.55324\n",
            "Epoch 30/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8015 - acc: 0.6310 - val_loss: 0.9572 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.55324\n",
            "Epoch 31/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.8036 - acc: 0.6319 - val_loss: 0.9589 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.55324\n",
            "Epoch 32/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7984 - acc: 0.6343 - val_loss: 0.9569 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.55324\n",
            "Epoch 33/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7968 - acc: 0.6332 - val_loss: 0.9596 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.55324\n",
            "Epoch 34/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7954 - acc: 0.6341 - val_loss: 0.9578 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.55324\n",
            "Epoch 35/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7925 - acc: 0.6374 - val_loss: 0.9601 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.55324\n",
            "Epoch 36/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7913 - acc: 0.6407 - val_loss: 0.9608 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.55324\n",
            "Epoch 37/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7881 - acc: 0.6418 - val_loss: 0.9621 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.55324\n",
            "Epoch 38/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7865 - acc: 0.6409 - val_loss: 0.9626 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.55324\n",
            "Epoch 39/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7848 - acc: 0.6452 - val_loss: 0.9630 - val_acc: 0.5383\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.55324\n",
            "Epoch 40/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7810 - acc: 0.6478 - val_loss: 0.9659 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.55324\n",
            "Epoch 41/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7795 - acc: 0.6462 - val_loss: 0.9645 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.55324\n",
            "Epoch 42/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7781 - acc: 0.6499 - val_loss: 0.9650 - val_acc: 0.5441\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.55324\n",
            "Epoch 43/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7764 - acc: 0.6503 - val_loss: 0.9660 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.55324\n",
            "Epoch 44/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.7728 - acc: 0.6555 - val_loss: 0.9677 - val_acc: 0.5452\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.55324\n",
            "Epoch 45/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7720 - acc: 0.6562 - val_loss: 0.9687 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.55324\n",
            "Epoch 46/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7681 - acc: 0.6590 - val_loss: 0.9684 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.55324\n",
            "Epoch 47/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7650 - acc: 0.6588 - val_loss: 0.9702 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.55324\n",
            "Epoch 48/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7629 - acc: 0.6599 - val_loss: 0.9715 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.55324\n",
            "Epoch 49/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7632 - acc: 0.6606 - val_loss: 0.9712 - val_acc: 0.5383\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.55324\n",
            "Epoch 50/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7566 - acc: 0.6669 - val_loss: 0.9730 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.55324\n",
            "Epoch 51/200\n",
            "15131/15131 [==============================] - 0s 5us/step - loss: 0.7559 - acc: 0.6664 - val_loss: 0.9752 - val_acc: 0.5356\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.55324\n",
            "Epoch 52/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7535 - acc: 0.6671 - val_loss: 0.9750 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.55324\n",
            "Epoch 53/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7525 - acc: 0.6664 - val_loss: 0.9760 - val_acc: 0.5356\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.55324\n",
            "Epoch 54/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7511 - acc: 0.6709 - val_loss: 0.9773 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.55324\n",
            "Epoch 55/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7463 - acc: 0.6705 - val_loss: 0.9778 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.55324\n",
            "Epoch 56/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7443 - acc: 0.6760 - val_loss: 0.9781 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.55324\n",
            "Epoch 57/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7420 - acc: 0.6754 - val_loss: 0.9800 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.55324\n",
            "Epoch 58/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7368 - acc: 0.6799 - val_loss: 0.9808 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.55324\n",
            "Epoch 59/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7387 - acc: 0.6784 - val_loss: 0.9827 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.55324\n",
            "Epoch 60/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7330 - acc: 0.6832 - val_loss: 0.9840 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.55324\n",
            "Epoch 61/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7309 - acc: 0.6865 - val_loss: 0.9837 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.55324\n",
            "Epoch 62/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7280 - acc: 0.6887 - val_loss: 0.9852 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.55324\n",
            "Epoch 63/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7227 - acc: 0.6867 - val_loss: 0.9866 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.55324\n",
            "Epoch 64/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7204 - acc: 0.6933 - val_loss: 0.9879 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.55324\n",
            "Epoch 65/200\n",
            "15131/15131 [==============================] - 0s 5us/step - loss: 0.7211 - acc: 0.6898 - val_loss: 0.9885 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.55324\n",
            "Epoch 66/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7157 - acc: 0.6931 - val_loss: 0.9908 - val_acc: 0.5420\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.55324\n",
            "Epoch 67/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7153 - acc: 0.6917 - val_loss: 0.9922 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.55324\n",
            "Epoch 68/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7090 - acc: 0.7020 - val_loss: 0.9948 - val_acc: 0.5431\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.55324\n",
            "Epoch 69/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.7078 - acc: 0.6958 - val_loss: 0.9960 - val_acc: 0.5431\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.55324\n",
            "Epoch 70/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6987 - acc: 0.7042 - val_loss: 0.9988 - val_acc: 0.5431\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.55324\n",
            "Epoch 71/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.7025 - acc: 0.7019 - val_loss: 0.9979 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.55324\n",
            "Epoch 72/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6987 - acc: 0.7035 - val_loss: 0.9985 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.55324\n",
            "Epoch 73/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6963 - acc: 0.7077 - val_loss: 1.0017 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.55324\n",
            "Epoch 74/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6956 - acc: 0.7072 - val_loss: 1.0029 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.55324\n",
            "Epoch 75/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6886 - acc: 0.7104 - val_loss: 1.0046 - val_acc: 0.5457\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.55324\n",
            "Epoch 76/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6862 - acc: 0.7150 - val_loss: 1.0090 - val_acc: 0.5452\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.55324\n",
            "Epoch 77/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6828 - acc: 0.7136 - val_loss: 1.0108 - val_acc: 0.5452\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.55324\n",
            "Epoch 78/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6835 - acc: 0.7116 - val_loss: 1.0153 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.55324\n",
            "Epoch 79/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6797 - acc: 0.7172 - val_loss: 1.0129 - val_acc: 0.5484\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.55324\n",
            "Epoch 80/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6780 - acc: 0.7169 - val_loss: 1.0149 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.55324\n",
            "Epoch 81/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6727 - acc: 0.7202 - val_loss: 1.0149 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.55324\n",
            "Epoch 82/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6706 - acc: 0.7168 - val_loss: 1.0202 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.55324\n",
            "Epoch 83/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6690 - acc: 0.7244 - val_loss: 1.0201 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.55324\n",
            "Epoch 84/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6645 - acc: 0.7222 - val_loss: 1.0214 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.55324\n",
            "Epoch 85/200\n",
            "15131/15131 [==============================] - 0s 5us/step - loss: 0.6597 - acc: 0.7242 - val_loss: 1.0249 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.55324\n",
            "Epoch 86/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6566 - acc: 0.7271 - val_loss: 1.0281 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.55324\n",
            "Epoch 87/200\n",
            "15131/15131 [==============================] - 0s 5us/step - loss: 0.6589 - acc: 0.7265 - val_loss: 1.0261 - val_acc: 0.5452\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.55324\n",
            "Epoch 88/200\n",
            "15131/15131 [==============================] - 0s 5us/step - loss: 0.6563 - acc: 0.7272 - val_loss: 1.0275 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.55324\n",
            "Epoch 89/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6477 - acc: 0.7326 - val_loss: 1.0320 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.55324\n",
            "Epoch 90/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6481 - acc: 0.7315 - val_loss: 1.0325 - val_acc: 0.5490\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.55324\n",
            "Epoch 91/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6502 - acc: 0.7284 - val_loss: 1.0349 - val_acc: 0.5516\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.55324\n",
            "Epoch 92/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6442 - acc: 0.7324 - val_loss: 1.0384 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.55324\n",
            "Epoch 93/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6414 - acc: 0.7372 - val_loss: 1.0402 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.55324\n",
            "Epoch 94/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.6401 - acc: 0.7360 - val_loss: 1.0418 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.55324\n",
            "Epoch 95/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.6408 - acc: 0.7359 - val_loss: 1.0397 - val_acc: 0.5457\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.55324\n",
            "Epoch 96/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.6355 - acc: 0.7399 - val_loss: 1.0427 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.55324\n",
            "Epoch 97/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6308 - acc: 0.7403 - val_loss: 1.0465 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.55324\n",
            "Epoch 98/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6330 - acc: 0.7407 - val_loss: 1.0497 - val_acc: 0.5350\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.55324\n",
            "Epoch 99/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6272 - acc: 0.7431 - val_loss: 1.0505 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.55324\n",
            "Epoch 100/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6246 - acc: 0.7459 - val_loss: 1.0541 - val_acc: 0.5383\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.55324\n",
            "Epoch 101/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6218 - acc: 0.7420 - val_loss: 1.0535 - val_acc: 0.5431\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.55324\n",
            "Epoch 102/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6242 - acc: 0.7443 - val_loss: 1.0573 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.55324\n",
            "Epoch 103/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6211 - acc: 0.7440 - val_loss: 1.0589 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.55324\n",
            "Epoch 104/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6112 - acc: 0.7499 - val_loss: 1.0633 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.55324\n",
            "Epoch 105/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6133 - acc: 0.7487 - val_loss: 1.0687 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.55324\n",
            "Epoch 106/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.6062 - acc: 0.7526 - val_loss: 1.0689 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.55324\n",
            "Epoch 107/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6185 - acc: 0.7450 - val_loss: 1.0688 - val_acc: 0.5420\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.55324\n",
            "Epoch 108/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6071 - acc: 0.7520 - val_loss: 1.0718 - val_acc: 0.5420\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.55324\n",
            "Epoch 109/200\n",
            "15131/15131 [==============================] - 0s 5us/step - loss: 0.6056 - acc: 0.7520 - val_loss: 1.0748 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.55324\n",
            "Epoch 110/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6030 - acc: 0.7551 - val_loss: 1.0771 - val_acc: 0.5441\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.55324\n",
            "Epoch 111/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6067 - acc: 0.7528 - val_loss: 1.0780 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.55324\n",
            "Epoch 112/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.6018 - acc: 0.7537 - val_loss: 1.0820 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.55324\n",
            "Epoch 113/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5975 - acc: 0.7553 - val_loss: 1.0839 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.55324\n",
            "Epoch 114/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5976 - acc: 0.7530 - val_loss: 1.0851 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.55324\n",
            "Epoch 115/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5927 - acc: 0.7609 - val_loss: 1.0848 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.55324\n",
            "Epoch 116/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5950 - acc: 0.7573 - val_loss: 1.0895 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.55324\n",
            "Epoch 117/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5845 - acc: 0.7608 - val_loss: 1.0977 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.55324\n",
            "Epoch 118/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5867 - acc: 0.7605 - val_loss: 1.0932 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.55324\n",
            "Epoch 119/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5871 - acc: 0.7583 - val_loss: 1.0963 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.55324\n",
            "Epoch 120/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5869 - acc: 0.7602 - val_loss: 1.0998 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.55324\n",
            "Epoch 121/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5820 - acc: 0.7647 - val_loss: 1.1035 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.55324\n",
            "Epoch 122/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5804 - acc: 0.7654 - val_loss: 1.1021 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.55324\n",
            "Epoch 123/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5781 - acc: 0.7652 - val_loss: 1.1037 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.55324\n",
            "Epoch 124/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5800 - acc: 0.7618 - val_loss: 1.1096 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.55324\n",
            "Epoch 125/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5735 - acc: 0.7687 - val_loss: 1.1106 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.55324\n",
            "Epoch 126/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5706 - acc: 0.7708 - val_loss: 1.1145 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.55324\n",
            "Epoch 127/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5713 - acc: 0.7658 - val_loss: 1.1109 - val_acc: 0.5415\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.55324\n",
            "Epoch 128/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5710 - acc: 0.7664 - val_loss: 1.1189 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.55324\n",
            "Epoch 129/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5677 - acc: 0.7686 - val_loss: 1.1185 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.55324\n",
            "Epoch 130/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5651 - acc: 0.7696 - val_loss: 1.1214 - val_acc: 0.5318\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.55324\n",
            "Epoch 131/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5647 - acc: 0.7707 - val_loss: 1.1262 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.55324\n",
            "Epoch 132/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5630 - acc: 0.7709 - val_loss: 1.1281 - val_acc: 0.5383\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.55324\n",
            "Epoch 133/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5606 - acc: 0.7740 - val_loss: 1.1304 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.55324\n",
            "Epoch 134/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5638 - acc: 0.7728 - val_loss: 1.1348 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.55324\n",
            "Epoch 135/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5612 - acc: 0.7690 - val_loss: 1.1328 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.55324\n",
            "Epoch 136/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5607 - acc: 0.7720 - val_loss: 1.1373 - val_acc: 0.5356\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.55324\n",
            "Epoch 137/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5590 - acc: 0.7733 - val_loss: 1.1425 - val_acc: 0.5356\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.55324\n",
            "Epoch 138/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5564 - acc: 0.7773 - val_loss: 1.1422 - val_acc: 0.5356\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.55324\n",
            "Epoch 139/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5550 - acc: 0.7724 - val_loss: 1.1474 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.55324\n",
            "Epoch 140/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5514 - acc: 0.7808 - val_loss: 1.1448 - val_acc: 0.5350\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.55324\n",
            "Epoch 141/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5535 - acc: 0.7747 - val_loss: 1.1473 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.55324\n",
            "Epoch 142/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5517 - acc: 0.7740 - val_loss: 1.1489 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.55324\n",
            "Epoch 143/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5479 - acc: 0.7760 - val_loss: 1.1560 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.55324\n",
            "Epoch 144/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5480 - acc: 0.7762 - val_loss: 1.1569 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.55324\n",
            "Epoch 145/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5450 - acc: 0.7799 - val_loss: 1.1540 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.55324\n",
            "Epoch 146/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5446 - acc: 0.7810 - val_loss: 1.1596 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.55324\n",
            "Epoch 147/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5454 - acc: 0.7798 - val_loss: 1.1538 - val_acc: 0.5318\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.55324\n",
            "Epoch 148/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5452 - acc: 0.7794 - val_loss: 1.1564 - val_acc: 0.5361\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.55324\n",
            "Epoch 149/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5428 - acc: 0.7803 - val_loss: 1.1590 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.55324\n",
            "Epoch 150/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5401 - acc: 0.7814 - val_loss: 1.1674 - val_acc: 0.5420\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.55324\n",
            "Epoch 151/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5360 - acc: 0.7851 - val_loss: 1.1708 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.55324\n",
            "Epoch 152/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5398 - acc: 0.7807 - val_loss: 1.1733 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.55324\n",
            "Epoch 153/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5330 - acc: 0.7869 - val_loss: 1.1789 - val_acc: 0.5367\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.55324\n",
            "Epoch 154/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5333 - acc: 0.7869 - val_loss: 1.1770 - val_acc: 0.5409\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.55324\n",
            "Epoch 155/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5302 - acc: 0.7859 - val_loss: 1.1787 - val_acc: 0.5372\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.55324\n",
            "Epoch 156/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5302 - acc: 0.7831 - val_loss: 1.1831 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.55324\n",
            "Epoch 157/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5316 - acc: 0.7844 - val_loss: 1.1870 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.55324\n",
            "Epoch 158/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5252 - acc: 0.7853 - val_loss: 1.1906 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.55324\n",
            "Epoch 159/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5270 - acc: 0.7871 - val_loss: 1.1923 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.55324\n",
            "Epoch 160/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5235 - acc: 0.7891 - val_loss: 1.1907 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.55324\n",
            "Epoch 161/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5239 - acc: 0.7898 - val_loss: 1.1896 - val_acc: 0.5393\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.55324\n",
            "Epoch 162/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5256 - acc: 0.7885 - val_loss: 1.1955 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.55324\n",
            "Epoch 163/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5261 - acc: 0.7882 - val_loss: 1.2019 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.55324\n",
            "Epoch 164/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5286 - acc: 0.7845 - val_loss: 1.2024 - val_acc: 0.5313\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.55324\n",
            "Epoch 165/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5184 - acc: 0.7938 - val_loss: 1.2050 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.55324\n",
            "Epoch 166/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5166 - acc: 0.7954 - val_loss: 1.2037 - val_acc: 0.5313\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.55324\n",
            "Epoch 167/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5213 - acc: 0.7879 - val_loss: 1.2020 - val_acc: 0.5297\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.55324\n",
            "Epoch 168/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5228 - acc: 0.7909 - val_loss: 1.2075 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.55324\n",
            "Epoch 169/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5158 - acc: 0.7912 - val_loss: 1.2035 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.55324\n",
            "Epoch 170/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5186 - acc: 0.7937 - val_loss: 1.2057 - val_acc: 0.5367\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.55324\n",
            "Epoch 171/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5214 - acc: 0.7923 - val_loss: 1.2059 - val_acc: 0.5377\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.55324\n",
            "Epoch 172/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5138 - acc: 0.7937 - val_loss: 1.2139 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.55324\n",
            "Epoch 173/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5155 - acc: 0.7925 - val_loss: 1.2132 - val_acc: 0.5270\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.55324\n",
            "Epoch 174/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5151 - acc: 0.7914 - val_loss: 1.2147 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.55324\n",
            "Epoch 175/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5120 - acc: 0.7931 - val_loss: 1.2202 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.55324\n",
            "Epoch 176/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5086 - acc: 0.7951 - val_loss: 1.2234 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.55324\n",
            "Epoch 177/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5042 - acc: 0.7960 - val_loss: 1.2266 - val_acc: 0.5313\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.55324\n",
            "Epoch 178/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5107 - acc: 0.7945 - val_loss: 1.2280 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.55324\n",
            "Epoch 179/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5078 - acc: 0.7959 - val_loss: 1.2302 - val_acc: 0.5297\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.55324\n",
            "Epoch 180/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5129 - acc: 0.7923 - val_loss: 1.2272 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.55324\n",
            "Epoch 181/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5084 - acc: 0.7964 - val_loss: 1.2311 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.55324\n",
            "Epoch 182/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5033 - acc: 0.7982 - val_loss: 1.2381 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.55324\n",
            "Epoch 183/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5028 - acc: 0.7963 - val_loss: 1.2370 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.55324\n",
            "Epoch 184/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5098 - acc: 0.7939 - val_loss: 1.2353 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.55324\n",
            "Epoch 185/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5046 - acc: 0.7974 - val_loss: 1.2366 - val_acc: 0.5297\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.55324\n",
            "Epoch 186/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5053 - acc: 0.7945 - val_loss: 1.2321 - val_acc: 0.5356\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.55324\n",
            "Epoch 187/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5056 - acc: 0.7976 - val_loss: 1.2394 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.55324\n",
            "Epoch 188/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.4990 - acc: 0.7991 - val_loss: 1.2413 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.55324\n",
            "Epoch 189/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5016 - acc: 0.7997 - val_loss: 1.2408 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.55324\n",
            "Epoch 190/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5025 - acc: 0.7961 - val_loss: 1.2382 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.55324\n",
            "Epoch 191/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.5001 - acc: 0.7990 - val_loss: 1.2438 - val_acc: 0.5292\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.55324\n",
            "Epoch 192/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.5002 - acc: 0.7988 - val_loss: 1.2484 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.55324\n",
            "Epoch 193/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.4968 - acc: 0.7970 - val_loss: 1.2414 - val_acc: 0.5308\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.55324\n",
            "Epoch 194/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.4939 - acc: 0.8014 - val_loss: 1.2498 - val_acc: 0.5297\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.55324\n",
            "Epoch 195/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.4983 - acc: 0.7973 - val_loss: 1.2568 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.55324\n",
            "Epoch 196/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.4949 - acc: 0.7980 - val_loss: 1.2573 - val_acc: 0.5334\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.55324\n",
            "Epoch 197/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.4879 - acc: 0.8054 - val_loss: 1.2622 - val_acc: 0.5340\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.55324\n",
            "Epoch 198/200\n",
            "15131/15131 [==============================] - 0s 7us/step - loss: 0.4902 - acc: 0.8032 - val_loss: 1.2601 - val_acc: 0.5350\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.55324\n",
            "Epoch 199/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.4927 - acc: 0.7992 - val_loss: 1.2648 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.55324\n",
            "Epoch 200/200\n",
            "15131/15131 [==============================] - 0s 6us/step - loss: 0.4890 - acc: 0.8051 - val_loss: 1.2631 - val_acc: 0.5286\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.55324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f776581b518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9aCd--dkXQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AyMeDiVkbmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d95b227d-10ed-4a15-f61f-415000b881cc"
      },
      "source": [
        "test_predictions = model.predict(test_embedding_)\n",
        "precision_recall_fscore_support(np.argmax(test_y,axis = 1),np.argmax(test_predictions,axis = 1),average='macro')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5685955675362454, 0.5431607887409783, 0.5503236012706578, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqGUSCV9eVth",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZAdwbzefTnk",
        "colab_type": "text"
      },
      "source": [
        "### Gaussian Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYREpwUyeVtb",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j8p5uu-MeVtZ",
        "colab": {}
      },
      "source": [
        "# trainpad = trainpad.reshape((-1,57))\n",
        "# testpad = testpad.reshape((-1,57))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8c0ffa65-9b61-4bb6-cf5d-194350033a61",
        "id": "ng-PRTWleVtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = GaussianNB()\n",
        "model.fit(train_embedding_, np.argmax(train_y,axis=1) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PxaZ-fPEeVtD",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(test_embedding_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VR0vQfNFeVs_",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "27b7dfe5-ad0c-4a79-c7d3-078e6d8d3a40",
        "id": "9g4Nle8MeVs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(np.argmax(test_y,axis=1), test_predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5034777956126271"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e65c3b86-cbe5-4f56-b892-81dfb6b42b54",
        "id": "HQNUUNLNeVs4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "precision_recall_fscore_support(np.argmax(test_y,axis = 1),test_predictions,average='macro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5125972811399809, 0.5018031028843198, 0.5015689418840493, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMFCz-TPfYNt",
        "colab_type": "text"
      },
      "source": [
        "### K-Nearest Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bcce4f4d-66be-45d8-89ea-6cb5ac895c4d",
        "id": "CS6MLARHeVs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = KNeighborsClassifier(n_neighbors=41)\n",
        "model.fit(train_embedding_, np.argmax(train_y,axis=1))\n",
        "test_predictions = model.predict(test_embedding_)\n",
        "accuracy_score(np.argmax(test_y,axis=1), test_predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48421615837346177"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4b815d1d-8444-4996-e41c-853510b297d4",
        "id": "jQSsve6feVsu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "precision_recall_fscore_support(np.argmax(test_y,axis = 1),test_predictions,average='macro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5306511271845491, 0.44973814582686283, 0.4443692614133994, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9QQzzBOeVsq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "16e491e5-1556-493d-f367-fb1aafc89a79",
        "id": "ne2I-TVveVsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        }
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"644pt\" viewBox=\"0.00 0.00 188.00 483.00\" width=\"251pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 479)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 184,-479 184,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140150790488752 -->\n<g class=\"node\" id=\"node1\">\n<title>140150790488752</title>\n<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 180,-474.5 180,-438.5 0,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-452.8\">dense_26_input: InputLayer</text>\n</g>\n<!-- 140150790488304 -->\n<g class=\"node\" id=\"node2\">\n<title>140150790488304</title>\n<polygon fill=\"none\" points=\"33,-365.5 33,-401.5 147,-401.5 147,-365.5 33,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-379.8\">dense_26: Dense</text>\n</g>\n<!-- 140150790488752&#45;&gt;140150790488304 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140150790488752-&gt;140150790488304</title>\n<path d=\"M90,-438.4551C90,-430.3828 90,-420.6764 90,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-411.5903 90,-401.5904 86.5001,-411.5904 93.5001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140150790488416 -->\n<g class=\"node\" id=\"node3\">\n<title>140150790488416</title>\n<polygon fill=\"none\" points=\"13,-292.5 13,-328.5 167,-328.5 167,-292.5 13,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-306.8\">activation_9: Activation</text>\n</g>\n<!-- 140150790488304&#45;&gt;140150790488416 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140150790488304-&gt;140150790488416</title>\n<path d=\"M90,-365.4551C90,-357.3828 90,-347.6764 90,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-338.5903 90,-328.5904 86.5001,-338.5904 93.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140150790489312 -->\n<g class=\"node\" id=\"node4\">\n<title>140150790489312</title>\n<polygon fill=\"none\" points=\"19.5,-219.5 19.5,-255.5 160.5,-255.5 160.5,-219.5 19.5,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-233.8\">dropout_17: Dropout</text>\n</g>\n<!-- 140150790488416&#45;&gt;140150790489312 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140150790488416-&gt;140150790489312</title>\n<path d=\"M90,-292.4551C90,-284.3828 90,-274.6764 90,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-265.5903 90,-255.5904 86.5001,-265.5904 93.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140150782127128 -->\n<g class=\"node\" id=\"node5\">\n<title>140150782127128</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 147,-182.5 147,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-160.8\">dense_27: Dense</text>\n</g>\n<!-- 140150790489312&#45;&gt;140150782127128 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140150790489312-&gt;140150782127128</title>\n<path d=\"M90,-219.4551C90,-211.3828 90,-201.6764 90,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-192.5903 90,-182.5904 86.5001,-192.5904 93.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140150782126008 -->\n<g class=\"node\" id=\"node6\">\n<title>140150782126008</title>\n<polygon fill=\"none\" points=\"19.5,-73.5 19.5,-109.5 160.5,-109.5 160.5,-73.5 19.5,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-87.8\">dropout_18: Dropout</text>\n</g>\n<!-- 140150782127128&#45;&gt;140150782126008 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140150782127128-&gt;140150782126008</title>\n<path d=\"M90,-146.4551C90,-138.3828 90,-128.6764 90,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-119.5903 90,-109.5904 86.5001,-119.5904 93.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140150781768592 -->\n<g class=\"node\" id=\"node7\">\n<title>140150781768592</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 147,-36.5 147,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-14.8\">dense_28: Dense</text>\n</g>\n<!-- 140150782126008&#45;&gt;140150781768592 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140150782126008-&gt;140150781768592</title>\n<path d=\"M90,-73.4551C90,-65.3828 90,-55.6764 90,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-46.5903 90,-36.5904 86.5001,-46.5904 93.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d30586c7-28bd-42ec-c7c1-ae530248f0f0",
        "id": "SfefFeyceVsg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png',show_shapes=True)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAALhCAIAAACrKoY8AAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nQROBQCCcAAVNBAKBcAIUNBEIBMIJ/gOx3wdQ7N5p7QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XrgRVxfxeVsb",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}